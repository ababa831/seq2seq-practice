{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種Seq2Seqモデルを試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple_seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seqの一番基本となる，LSTMによるencoder-decoderモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, CuDNNLSTM\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "def get_wakati(text, reverse=False, offset=False):\n",
    "    \"\"\"\n",
    "    text: 文書(str) \n",
    "    reverse=Trueの場合は，文字の並びを反転させる．（seq2seqでは，入力系列は反転しなければならない！）\n",
    "    offset=Trueの場合は，タイムステップ文\n",
    "    \"\"\"\n",
    "    wakati_list = t.tokenize(text, wakati=True)\n",
    "    if reverse == True:\n",
    "        wakati_list = list(reversed(wakati_list))\n",
    "    return \" \".join(wakati_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_count(df, target_cols):\n",
    "    total_word_count = Counter()\n",
    "    for col in target_cols:\n",
    "        for text in df[col]: \n",
    "            total_word_count += Counter(text.split())\n",
    "    #print(total_word_count.keys())\n",
    "    return len(total_word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charlen_count(df, target_colname):\n",
    "    df[\"tmp_wlist\"] = df[target_colname].str.split()\n",
    "    df[target_colname+\"_charlen\"] = df[\"tmp_wlist\"].apply(lambda x: len(x))\n",
    "    df = df.drop([\"tmp_wlist\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(new_params=None):\n",
    "    \"\"\"\n",
    "    最も基本的な4層LSTMによる，encoder-decoderモデル\n",
    "    Ref: https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "    \n",
    "    hyper_params: カスタム設定したハイパーパラメータ\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"seq_maxlen\": 139,\n",
    "        \"num_words\": 1592,\n",
    "        \"vec_len\": 128,\n",
    "        \"learning_rate\": 0.002,\n",
    "        #\"dropout_rate\": 0.5,\n",
    "        \"loss_func\": \"categorical_crossentropy\",\n",
    "        \"metrics\": [\"accuracy\"]\n",
    "    }\n",
    "    if new_params != None:\n",
    "        params.update(new_params)\n",
    "        \n",
    "    enc_inp = Input(shape=(params[\"seq_maxlen\"], params[\"num_words\"]))\n",
    "    # decoder初期化用の内部状態を得る\n",
    "    enc_out, state_h, state_c = CuDNNLSTM(params[\"vec_len\"], return_sequences=True, return_state=True)(enc_inp)\n",
    "    enc_states = [state_h, state_c]\n",
    "    \n",
    "    dec_out = CuDNNLSTM(params[\"vec_len\"], return_sequences=True)(enc_out, initial_state=enc_states)\n",
    "    seq_out = Dense(params[\"num_words\"], activation=\"softmax\")(dec_out)\n",
    "    \n",
    "    model = Model(inputs=enc_inp, outputs=seq_out)\n",
    "    model.compile(loss=params[\"loss_func\"], \n",
    "                  optimizer=Adam(lr=params[\"learning_rate\"]),\n",
    "                  metrics=params[\"metrics\"]) # BLEUスコアで評価したいが，Kerasでは難しいので取り敢えず正解率で設定\n",
    "    model.summary() # モデルの構成を表示\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__text</th>\n",
       "      <th>reaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>おはきゃーっと！</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ねこますかわいいいいい</td>\n",
       "      <td>ありがと♡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>のら！ちゃん！べりべりきゅーと！</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>おはきゃーっと！</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🔥猫松🔥</td>\n",
       "      <td>猫松さんが燃やされていますね</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             __text        reaction\n",
       "0          おはきゃーっと！         neglect\n",
       "1       ねこますかわいいいいい           ありがと♡\n",
       "2  のら！ちゃん！べりべりきゅーと！         neglect\n",
       "3          おはきゃーっと！         neglect\n",
       "4              🔥猫松🔥  猫松さんが燃やされていますね"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データは各自用意する．\n",
    "train_df = pd.read_csv(\"seq2seq_sample.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__text</th>\n",
       "      <th>reaction</th>\n",
       "      <th>wakati_enc_in</th>\n",
       "      <th>wakati_dec_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>おはきゃーっと！</td>\n",
       "      <td>neglect</td>\n",
       "      <td>！ っと きゃー は お</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ねこますかわいいいいい</td>\n",
       "      <td>ありがと♡</td>\n",
       "      <td>いい いい わい か ます ねこ</td>\n",
       "      <td>ありがと ♡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>のら！ちゃん！べりべりきゅーと！</td>\n",
       "      <td>neglect</td>\n",
       "      <td>！ と ー ゅ き べり べり ！ ちゃん ！ のら</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>おはきゃーっと！</td>\n",
       "      <td>neglect</td>\n",
       "      <td>！ っと きゃー は お</td>\n",
       "      <td>neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🔥猫松🔥</td>\n",
       "      <td>猫松さんが燃やされていますね</td>\n",
       "      <td>🔥 松 猫 🔥</td>\n",
       "      <td>猫 松 さん が 燃やさ れ て い ます ね</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             __text        reaction               wakati_enc_in  \\\n",
       "0          おはきゃーっと！         neglect                ！ っと きゃー は お   \n",
       "1       ねこますかわいいいいい           ありがと♡            いい いい わい か ます ねこ   \n",
       "2  のら！ちゃん！べりべりきゅーと！         neglect  ！ と ー ゅ き べり べり ！ ちゃん ！ のら   \n",
       "3          おはきゃーっと！         neglect                ！ っと きゃー は お   \n",
       "4              🔥猫松🔥  猫松さんが燃やされていますね                     🔥 松 猫 🔥   \n",
       "\n",
       "            wakati_dec_out  \n",
       "0                  neglect  \n",
       "1                   ありがと ♡  \n",
       "2                  neglect  \n",
       "3                  neglect  \n",
       "4  猫 松 さん が 燃やさ れ て い ます ね  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"wakati_enc_in\"] = train_df[\"__text\"].apply(lambda x: get_wakati(x, reverse=True))\n",
    "train_df[\"wakati_dec_out\"] = train_df[\"reaction\"].apply(lambda x: get_wakati(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの語彙数を計算する\n",
    "target_cols = [\"wakati_enc_in\", \"wakati_dec_out\"]\n",
    "num_words = words_count(train_df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_cols:\n",
    "    train_df = charlen_count(train_df, target_colname=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系列長順に並べ替える，ミニバッチ学習で系列長の差を小さくするため．\n",
    "train_df = train_df.sort_values(by=target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストを数値ベクトル表現に変換する\n",
    "# 1. 変換器の学習\n",
    "tokenizer = text.Tokenizer(num_words=num_words)\n",
    "inout_text_list = []\n",
    "for col in target_cols:\n",
    "    inout_text_list += train_df[col].tolist()\n",
    "tokenizer.fit_on_texts(inout_text_list)\n",
    "# 2. 最大の系列長を計算\n",
    "inout_text_len = [len(text) for text in inout_text_list]\n",
    "seq_maxlen = np.max(inout_text_len)\n",
    "# 3. 数値ベクトルに変換\n",
    "token_enc_in = tokenizer.texts_to_sequences(train_df[\"wakati_enc_in\"].values)\n",
    "token_dec_out = tokenizer.texts_to_sequences(train_df[\"wakati_dec_out\"].values)\n",
    "# 4. 系列長を揃える\n",
    "token_enc_in = sequence.pad_sequences(token_enc_in, maxlen=seq_maxlen)\n",
    "token_dec_out = sequence.pad_sequences(token_dec_out, maxlen=seq_maxlen)\n",
    "# 5. one-hot形式に変換\n",
    "onehot_enc_in = np_utils.to_categorical(token_enc_in, num_classes=num_words) \n",
    "onehot_dec_out = np_utils.to_categorical(token_dec_out, num_classes=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数値ベクトルに変換した特徴量の例\n",
    "token_dec_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0は文字列なし，1はEOS．それ以外は，単語が数値に変換されている\n",
    "逆変換する場合は，1以上の要素を抽出して，\n",
    "\n",
    "```\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "```\n",
    "\n",
    "で逆変換の辞書を作成して，系列を求めればよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_dec_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数値データに戻す方法\n",
    "np.argmax(onehot_dec_out[0,138,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akio\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 139, 1590)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 139, 128), ( 880640      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)        (None, 139, 128)     132096      cu_dnnlstm_1[0][0]               \n",
      "                                                                 cu_dnnlstm_1[0][1]               \n",
      "                                                                 cu_dnnlstm_1[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 139, 1590)    205110      cu_dnnlstm_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,217,846\n",
      "Trainable params: 1,217,846\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3878 samples, validate on 431 samples\n",
      "Epoch 1/90\n",
      "3878/3878 [==============================] - 29s 7ms/step - loss: 2.1796 - acc: 0.9526 - val_loss: 0.8353 - val_acc: 0.9361\n",
      "Epoch 2/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0970 - acc: 0.9886 - val_loss: 0.8993 - val_acc: 0.9361\n",
      "Epoch 3/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0892 - acc: 0.9886 - val_loss: 0.8836 - val_acc: 0.9361\n",
      "Epoch 4/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0885 - acc: 0.9886 - val_loss: 0.8696 - val_acc: 0.9361\n",
      "Epoch 5/90\n",
      "3878/3878 [==============================] - 22s 6ms/step - loss: 0.0889 - acc: 0.9886 - val_loss: 0.8630 - val_acc: 0.9361\n",
      "Epoch 6/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0877 - acc: 0.9886 - val_loss: 0.8513 - val_acc: 0.9361\n",
      "Epoch 7/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0876 - acc: 0.9886 - val_loss: 0.8358 - val_acc: 0.9361\n",
      "Epoch 8/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0877 - acc: 0.9886 - val_loss: 0.8488 - val_acc: 0.9361\n",
      "Epoch 9/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0865 - acc: 0.9886 - val_loss: 0.8326 - val_acc: 0.9361\n",
      "Epoch 10/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0877 - acc: 0.9886 - val_loss: 0.8232 - val_acc: 0.9361\n",
      "Epoch 11/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0875 - acc: 0.9886 - val_loss: 0.8244 - val_acc: 0.9361\n",
      "Epoch 12/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0853 - acc: 0.9886 - val_loss: 0.8178 - val_acc: 0.9361\n",
      "Epoch 13/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0848 - acc: 0.9886 - val_loss: 0.8134 - val_acc: 0.9361\n",
      "Epoch 14/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0851 - acc: 0.9886 - val_loss: 0.8119 - val_acc: 0.9361\n",
      "Epoch 15/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0837 - acc: 0.9886 - val_loss: 0.8181 - val_acc: 0.9361\n",
      "Epoch 16/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0819 - acc: 0.9886 - val_loss: 0.8066 - val_acc: 0.9361\n",
      "Epoch 17/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0820 - acc: 0.9886 - val_loss: 0.8084 - val_acc: 0.9361\n",
      "Epoch 18/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0810 - acc: 0.9886 - val_loss: 0.8105 - val_acc: 0.9361\n",
      "Epoch 19/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0807 - acc: 0.9886 - val_loss: 0.8096 - val_acc: 0.9361\n",
      "Epoch 20/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0811 - acc: 0.9886 - val_loss: 0.8050 - val_acc: 0.9361\n",
      "Epoch 21/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0796 - acc: 0.9886 - val_loss: 0.8081 - val_acc: 0.9361\n",
      "Epoch 22/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0792 - acc: 0.9886 - val_loss: 0.8120 - val_acc: 0.9361\n",
      "Epoch 23/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0789 - acc: 0.9886 - val_loss: 0.8202 - val_acc: 0.9361\n",
      "Epoch 24/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0790 - acc: 0.9886 - val_loss: 0.8060 - val_acc: 0.9361\n",
      "Epoch 25/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0767 - acc: 0.9886 - val_loss: 0.8042 - val_acc: 0.9361\n",
      "Epoch 26/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0770 - acc: 0.9886 - val_loss: 0.7940 - val_acc: 0.9361\n",
      "Epoch 27/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0783 - acc: 0.9886 - val_loss: 0.8118 - val_acc: 0.9361\n",
      "Epoch 28/90\n",
      "3878/3878 [==============================] - 22s 6ms/step - loss: 0.0783 - acc: 0.9886 - val_loss: 0.8074 - val_acc: 0.9361\n",
      "Epoch 29/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0758 - acc: 0.9886 - val_loss: 0.7940 - val_acc: 0.9361\n",
      "Epoch 30/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0742 - acc: 0.9886 - val_loss: 0.7926 - val_acc: 0.9361\n",
      "Epoch 31/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0745 - acc: 0.9886 - val_loss: 0.8029 - val_acc: 0.9361\n",
      "Epoch 32/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0725 - acc: 0.9886 - val_loss: 0.7998 - val_acc: 0.9361\n",
      "Epoch 33/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0710 - acc: 0.9886 - val_loss: 0.7874 - val_acc: 0.9361\n",
      "Epoch 34/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0688 - acc: 0.9886 - val_loss: 0.7984 - val_acc: 0.9361\n",
      "Epoch 35/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0672 - acc: 0.9886 - val_loss: 0.8135 - val_acc: 0.9361\n",
      "Epoch 36/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0661 - acc: 0.9886 - val_loss: 0.7821 - val_acc: 0.9361\n",
      "Epoch 37/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0653 - acc: 0.9886 - val_loss: 0.7924 - val_acc: 0.9361\n",
      "Epoch 38/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0631 - acc: 0.9886 - val_loss: 0.7889 - val_acc: 0.9361\n",
      "Epoch 39/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0608 - acc: 0.9886 - val_loss: 0.7776 - val_acc: 0.9361\n",
      "Epoch 40/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0600 - acc: 0.9886 - val_loss: 0.7833 - val_acc: 0.9361\n",
      "Epoch 41/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0600 - acc: 0.9886 - val_loss: 0.7845 - val_acc: 0.9361\n",
      "Epoch 42/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0592 - acc: 0.9886 - val_loss: 0.7912 - val_acc: 0.9361\n",
      "Epoch 43/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0577 - acc: 0.9886 - val_loss: 0.7691 - val_acc: 0.9361\n",
      "Epoch 44/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0562 - acc: 0.9886 - val_loss: 0.7743 - val_acc: 0.9361\n",
      "Epoch 45/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0549 - acc: 0.9886 - val_loss: 0.7768 - val_acc: 0.9361\n",
      "Epoch 46/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0536 - acc: 0.9886 - val_loss: 0.7619 - val_acc: 0.9361\n",
      "Epoch 47/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0530 - acc: 0.9886 - val_loss: 0.7806 - val_acc: 0.9361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0541 - acc: 0.9886 - val_loss: 0.7663 - val_acc: 0.9361\n",
      "Epoch 49/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0516 - acc: 0.9886 - val_loss: 0.7837 - val_acc: 0.9361\n",
      "Epoch 50/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0513 - acc: 0.9886 - val_loss: 0.7657 - val_acc: 0.9361\n",
      "Epoch 51/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0517 - acc: 0.9887 - val_loss: 0.7649 - val_acc: 0.9361\n",
      "Epoch 52/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0516 - acc: 0.9886 - val_loss: 0.7472 - val_acc: 0.9361\n",
      "Epoch 53/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0503 - acc: 0.9886 - val_loss: 0.7702 - val_acc: 0.9361\n",
      "Epoch 54/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0505 - acc: 0.9886 - val_loss: 0.7483 - val_acc: 0.9361\n",
      "Epoch 55/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0489 - acc: 0.9886 - val_loss: 0.7705 - val_acc: 0.9367\n",
      "Epoch 56/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0479 - acc: 0.9894 - val_loss: 0.7741 - val_acc: 0.9361\n",
      "Epoch 57/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0763 - acc: 0.9761 - val_loss: 0.8507 - val_acc: 0.9361\n",
      "Epoch 58/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.1033 - acc: 0.9886 - val_loss: 0.7896 - val_acc: 0.9361\n",
      "Epoch 59/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0861 - acc: 0.9886 - val_loss: 0.8118 - val_acc: 0.9361\n",
      "Epoch 60/90\n",
      "3878/3878 [==============================] - 23s 6ms/step - loss: 0.0741 - acc: 0.9886 - val_loss: 0.8063 - val_acc: 0.9361\n",
      "Epoch 61/90\n",
      "3878/3878 [==============================] - 31s 8ms/step - loss: 0.0672 - acc: 0.9886 - val_loss: 0.7930 - val_acc: 0.9361\n",
      "Epoch 62/90\n",
      "3878/3878 [==============================] - 23s 6ms/step - loss: 0.0546 - acc: 0.9886 - val_loss: 0.7709 - val_acc: 0.9361\n",
      "Epoch 63/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0528 - acc: 0.9886 - val_loss: 0.7790 - val_acc: 0.9361\n",
      "Epoch 64/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0519 - acc: 0.9886 - val_loss: 0.7708 - val_acc: 0.9361\n",
      "Epoch 65/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0515 - acc: 0.9886 - val_loss: 0.7696 - val_acc: 0.9361\n",
      "Epoch 66/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0513 - acc: 0.9886 - val_loss: 0.7648 - val_acc: 0.9361\n",
      "Epoch 67/90\n",
      "3878/3878 [==============================] - 21s 6ms/step - loss: 0.0509 - acc: 0.9894 - val_loss: 0.7755 - val_acc: 0.9361\n",
      "Epoch 68/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0494 - acc: 0.9886 - val_loss: 0.7760 - val_acc: 0.9361\n",
      "Epoch 69/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0486 - acc: 0.9887 - val_loss: 0.7820 - val_acc: 0.9363\n",
      "Epoch 70/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0476 - acc: 0.9905 - val_loss: 0.7629 - val_acc: 0.9368\n",
      "Epoch 71/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0473 - acc: 0.9916 - val_loss: 0.7428 - val_acc: 0.9368\n",
      "Epoch 72/90\n",
      "3878/3878 [==============================] - 21s 6ms/step - loss: 0.0463 - acc: 0.9897 - val_loss: 0.7504 - val_acc: 0.9368\n",
      "Epoch 73/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0450 - acc: 0.9914 - val_loss: 0.7507 - val_acc: 0.9368\n",
      "Epoch 74/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0455 - acc: 0.9909 - val_loss: 0.7366 - val_acc: 0.9368\n",
      "Epoch 75/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0436 - acc: 0.9915 - val_loss: 0.7706 - val_acc: 0.9368\n",
      "Epoch 76/90\n",
      "3878/3878 [==============================] - 21s 6ms/step - loss: 0.0441 - acc: 0.9914 - val_loss: 0.7512 - val_acc: 0.9368\n",
      "Epoch 77/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0448 - acc: 0.9915 - val_loss: 0.7653 - val_acc: 0.9368\n",
      "Epoch 78/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0439 - acc: 0.9914 - val_loss: 0.7416 - val_acc: 0.9369\n",
      "Epoch 79/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0425 - acc: 0.9916 - val_loss: 0.7558 - val_acc: 0.9368\n",
      "Epoch 80/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0430 - acc: 0.9918 - val_loss: 0.7333 - val_acc: 0.9368\n",
      "Epoch 81/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.7475 - val_acc: 0.9368\n",
      "Epoch 82/90\n",
      "3878/3878 [==============================] - 21s 6ms/step - loss: 0.0425 - acc: 0.9917 - val_loss: 0.7489 - val_acc: 0.9368\n",
      "Epoch 83/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0412 - acc: 0.9924 - val_loss: 0.7375 - val_acc: 0.9368\n",
      "Epoch 84/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0414 - acc: 0.9916 - val_loss: 0.7117 - val_acc: 0.9361\n",
      "Epoch 85/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0401 - acc: 0.9915 - val_loss: 0.7252 - val_acc: 0.9368\n",
      "Epoch 86/90\n",
      "3878/3878 [==============================] - 22s 6ms/step - loss: 0.0390 - acc: 0.9927 - val_loss: 0.7481 - val_acc: 0.9368\n",
      "Epoch 87/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0384 - acc: 0.9925 - val_loss: 0.7517 - val_acc: 0.9368\n",
      "Epoch 88/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0399 - acc: 0.9923 - val_loss: 0.7209 - val_acc: 0.9368\n",
      "Epoch 89/90\n",
      "3878/3878 [==============================] - 20s 5ms/step - loss: 0.0370 - acc: 0.9928 - val_loss: 0.7063 - val_acc: 0.9368\n",
      "Epoch 90/90\n",
      "3878/3878 [==============================] - 21s 5ms/step - loss: 0.0366 - acc: 0.9931 - val_loss: 0.6843 - val_acc: 0.9368\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"seq_maxlen\": seq_maxlen,\n",
    "    \"num_words\": num_words,\n",
    "    \"vec_len\": 128,\n",
    "    \"learning_rate\": 0.002,\n",
    "    #\"dropout_rate\": 0.5,\n",
    "    \"loss_func\": \"categorical_crossentropy\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "\n",
    "model = seq2seq_model(params)\n",
    "# batchは論文を参考に設定．最適化はしていない\n",
    "# epochsはある程度回さないと最適解に到達しない！\n",
    "batch_size = 128\n",
    "epochs = 90\n",
    "history = model.fit(onehot_enc_in, onehot_dec_out, \n",
    "                    batch_size=batch_size, epochs=epochs, validation_split=0.1, \n",
    "                    shuffle=\"batch\", # バッチデータ内でシャッフルする \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定対称の入力系列を用意\n",
    "example_testtext = \"ねこますかわいいいいい\" \n",
    "wakati_testtext= get_wakati(example_testtext, reverse=True)\n",
    "# 数値ベクトルに変換　tokenizerは学習データの特徴量を作成したときのモデルを使用\n",
    "token_testinput = tokenizer.texts_to_sequences(np.array([wakati_testtext]))\n",
    "# 系列長を揃える\n",
    "token_testinput = sequence.pad_sequences(token_testinput, maxlen=seq_maxlen)\n",
    "# one-hot表現に変換\n",
    "onehot_testinput = np_utils.to_categorical(token_testinput, num_classes=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "onehot_test_output = model.predict(onehot_testinput, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.9475431e-01, 1.7740836e-04, 1.1747601e-06, ...,\n",
       "         1.1553026e-06, 1.3781611e-06, 1.3927983e-06],\n",
       "        [9.9807692e-01, 2.5602206e-04, 3.1289243e-08, ...,\n",
       "         3.0148879e-08, 4.7967795e-08, 4.1928526e-08],\n",
       "        [9.9817407e-01, 2.8862883e-04, 1.5719570e-08, ...,\n",
       "         1.5231048e-08, 2.5864795e-08, 2.1755719e-08],\n",
       "        ...,\n",
       "        [9.8426211e-01, 3.4647244e-03, 3.0715867e-08, ...,\n",
       "         2.8256336e-08, 4.6093803e-08, 3.8952599e-08],\n",
       "        [7.7308244e-01, 9.3649246e-02, 9.4877919e-08, ...,\n",
       "         8.0581763e-08, 1.2930089e-07, 1.1510024e-07],\n",
       "        [1.9019218e-01, 5.3921276e-01, 7.1187365e-08, ...,\n",
       "         5.6246751e-08, 8.9453629e-08, 8.1284341e-08]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定したone-hotデータを数値ベクトルに変換する\n",
    "token_testoutput = [np.argmax(seq_val) for seq_val in onehot_test_output[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'neglect',\n",
       " 2: '！',\n",
       " 3: '♡',\n",
       " 4: 'ありがと',\n",
       " 5: 'かわいい',\n",
       " 6: 'お',\n",
       " 7: 'て',\n",
       " 8: '松',\n",
       " 9: '猫',\n",
       " 10: '🔥',\n",
       " 11: 'ます',\n",
       " 12: '草',\n",
       " 13: 'い',\n",
       " 14: 'ー',\n",
       " 15: 'が',\n",
       " 16: 'さん',\n",
       " 17: 'おお',\n",
       " 18: 'ね',\n",
       " 19: 'れ',\n",
       " 20: '？',\n",
       " 21: '燃やさ',\n",
       " 22: 'の',\n",
       " 23: 'べり',\n",
       " 24: 'おい',\n",
       " 25: 'いい',\n",
       " 26: 'た',\n",
       " 27: 'のら',\n",
       " 28: 'じゃ',\n",
       " 29: 'で',\n",
       " 30: 'き',\n",
       " 31: 'と',\n",
       " 32: '～',\n",
       " 33: 'あら',\n",
       " 34: 'し',\n",
       " 35: '＾',\n",
       " 36: 'ない',\n",
       " 37: 'ゅ',\n",
       " 38: 'つ',\n",
       " 39: 'う',\n",
       " 40: 'は',\n",
       " 41: 'っと',\n",
       " 42: 'また',\n",
       " 43: 'こく',\n",
       " 44: 'きゃー',\n",
       " 45: 'やっ',\n",
       " 46: 'わかる',\n",
       " 47: 'か',\n",
       " 48: 'ひじき',\n",
       " 49: 'いか',\n",
       " 50: 'わかり',\n",
       " 51: '今度',\n",
       " 52: '会い',\n",
       " 53: 'ましょ',\n",
       " 54: 'ちゃん',\n",
       " 55: '・',\n",
       " 56: 'に',\n",
       " 57: 'お前',\n",
       " 58: 'ｗ',\n",
       " 59: 'ｗｗｗｗ',\n",
       " 60: 'も',\n",
       " 61: 'な',\n",
       " 62: 'おまえ',\n",
       " 63: '🔥🔥',\n",
       " 64: '🔥🔥🔥',\n",
       " 65: 'おじ',\n",
       " 66: 'お疲れ様',\n",
       " 67: 'だ',\n",
       " 68: 'おおお',\n",
       " 69: 'でし',\n",
       " 70: '…',\n",
       " 71: 'を',\n",
       " 72: 'よ',\n",
       " 73: '皆さん',\n",
       " 74: '，',\n",
       " 75: 'ゃっち',\n",
       " 76: 'み',\n",
       " 77: 'かわい',\n",
       " 78: 'ｗｗｗｗｗ',\n",
       " 79: 'ん',\n",
       " 80: 'やつ',\n",
       " 81: 'てる',\n",
       " 82: 'から',\n",
       " 83: 'マン',\n",
       " 84: 'です',\n",
       " 85: 'おじさん',\n",
       " 86: '、',\n",
       " 87: 'ま',\n",
       " 88: 'ｗｗｗｗｗｗ',\n",
       " 89: 'け',\n",
       " 90: 'おる',\n",
       " 91: 'さ',\n",
       " 92: 'つかれ',\n",
       " 93: 'ぞ',\n",
       " 94: 'じゃい',\n",
       " 95: '国王',\n",
       " 96: '悩み',\n",
       " 97: 'もみ',\n",
       " 98: 'ああ',\n",
       " 99: 'おっ',\n",
       " 100: 'わ',\n",
       " 101: 'w',\n",
       " 102: 'やり',\n",
       " 103: '。',\n",
       " 104: 'まで',\n",
       " 105: 'さま',\n",
       " 106: 'これ',\n",
       " 107: 'そう',\n",
       " 108: '\\u3000',\n",
       " 109: 'ガチ',\n",
       " 110: 'なぁ',\n",
       " 111: 'え',\n",
       " 112: '人',\n",
       " 113: 'あー',\n",
       " 114: 'め',\n",
       " 115: 'おもい',\n",
       " 116: 'マーン',\n",
       " 117: 'ｗｗｗｗｗｗｗ',\n",
       " 118: '夜',\n",
       " 119: '名前',\n",
       " 120: 'ある',\n",
       " 121: 'する',\n",
       " 122: 'おぉ',\n",
       " 123: 'おめでとう',\n",
       " 124: '勢',\n",
       " 125: '🔥🔥🔥🔥🔥',\n",
       " 126: 'ねこ',\n",
       " 127: 'はじまる',\n",
       " 128: 'おしり',\n",
       " 129: 'ｗｗｗｗｗｗｗｗ',\n",
       " 130: 'ｗｗｗｗｗｗｗｗｗ',\n",
       " 131: '🔥🔥🔥🔥',\n",
       " 132: 'ら',\n",
       " 133: 'あ',\n",
       " 134: 'おじいちゃん',\n",
       " 135: '」',\n",
       " 136: 'すぎ',\n",
       " 137: '重い',\n",
       " 138: 'おにぎり',\n",
       " 139: '好き',\n",
       " 140: 'おつき',\n",
       " 141: 'ｗｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 142: '脇',\n",
       " 143: 'よろしく',\n",
       " 144: 'って',\n",
       " 145: 'おや',\n",
       " 146: 'ば',\n",
       " 147: 'おう',\n",
       " 148: 'ここ',\n",
       " 149: 'コメント',\n",
       " 150: 'や',\n",
       " 151: 'ゃっと',\n",
       " 152: 'おし',\n",
       " 153: '三',\n",
       " 154: '夫',\n",
       " 155: 'ｗｗｗ',\n",
       " 156: 'ｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 157: '🔥🔥🔥🔥🔥🔥🔥🔥',\n",
       " 158: 'きゃ',\n",
       " 159: 'らち',\n",
       " 160: '♪',\n",
       " 161: '「',\n",
       " 162: 'なっ',\n",
       " 163: '早口',\n",
       " 164: 'なん',\n",
       " 165: 'ムーブ',\n",
       " 166: 'におい',\n",
       " 167: 'ほ',\n",
       " 168: '気',\n",
       " 169: 'なあ',\n",
       " 170: '二',\n",
       " 171: 'おしい',\n",
       " 172: 'がけ',\n",
       " 173: 'だっ',\n",
       " 174: '回',\n",
       " 175: '出す',\n",
       " 176: '顔',\n",
       " 177: '回答',\n",
       " 178: 'なー',\n",
       " 179: 'おねがい',\n",
       " 180: 'ゃんてぃ',\n",
       " 181: '）',\n",
       " 182: '（',\n",
       " 183: 'プライベート',\n",
       " 184: 'ｋ',\n",
       " 185: 'ぶ',\n",
       " 186: '感',\n",
       " 187: 'す',\n",
       " 188: 'たい',\n",
       " 189: 'ご',\n",
       " 190: 'たら',\n",
       " 191: 'どう',\n",
       " 192: 'くれ',\n",
       " 193: 'よお',\n",
       " 194: 'おしゃれ',\n",
       " 195: 'ねずみ',\n",
       " 196: 'ーー',\n",
       " 197: 'なお',\n",
       " 198: 'kawaii',\n",
       " 199: 'なんか',\n",
       " 200: '投げ',\n",
       " 201: 'けど',\n",
       " 202: 'しり',\n",
       " 203: 'すぎる',\n",
       " 204: 'テレビ',\n",
       " 205: '体操',\n",
       " 206: 'ねぇ',\n",
       " 207: '貫通',\n",
       " 208: 'パロスペシャル',\n",
       " 209: '香辛料',\n",
       " 210: 'それ',\n",
       " 211: '士',\n",
       " 212: '銃',\n",
       " 213: 'ｗｗｗｗｗｗｗｗｗｗ',\n",
       " 214: 'ｗｗｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 215: 'ｗｗｗｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 216: '～～',\n",
       " 217: '🔥🔥🔥🔥🔥🔥🔥🔥🔥',\n",
       " 218: 'お疲れさま',\n",
       " 219: 'perm',\n",
       " 220: 'る',\n",
       " 221: 'っきり',\n",
       " 222: 'お札',\n",
       " 223: 'もっと',\n",
       " 224: 'ちゃ',\n",
       " 225: 'スタッフ',\n",
       " 226: '買お',\n",
       " 227: '乳',\n",
       " 228: '神',\n",
       " 229: '拡張',\n",
       " 230: 'がに股',\n",
       " 231: 'この',\n",
       " 232: 'お願い',\n",
       " 233: '親分',\n",
       " 234: 'ぃ',\n",
       " 235: 'おいで',\n",
       " 236: 'いく',\n",
       " 237: 'ガニ',\n",
       " 238: 'まだ',\n",
       " 239: 'でしょ',\n",
       " 240: 'なく',\n",
       " 241: 'ぽんこつ',\n",
       " 242: 'めっちゃ',\n",
       " 243: 'あれ',\n",
       " 244: 'やん',\n",
       " 245: '相談',\n",
       " 246: 'おん',\n",
       " 247: 'すこ',\n",
       " 248: 'すごい',\n",
       " 249: '股',\n",
       " 250: '一',\n",
       " 251: '民',\n",
       " 252: 'まし',\n",
       " 253: '美術館',\n",
       " 254: '辛い',\n",
       " 255: 'しか',\n",
       " 256: 'ウーマン',\n",
       " 257: 'ショット',\n",
       " 258: '笑う',\n",
       " 259: '駐車',\n",
       " 260: '縦列',\n",
       " 261: 'マジ',\n",
       " 262: 'a',\n",
       " 263: 'u',\n",
       " 264: '募集',\n",
       " 265: '燃え',\n",
       " 266: '火',\n",
       " 267: 'トラッカー',\n",
       " 268: 'ください',\n",
       " 269: 'いたし',\n",
       " 270: '】',\n",
       " 271: '【',\n",
       " 272: 'インフィニットループ',\n",
       " 273: 'もう',\n",
       " 274: '本家',\n",
       " 275: 'わい',\n",
       " 276: 'クッソ',\n",
       " 277: 'ふ',\n",
       " 278: 'だろ',\n",
       " 279: 'おいおい',\n",
       " 280: 'ほお',\n",
       " 281: 'なる',\n",
       " 282: '日',\n",
       " 283: '透明',\n",
       " 284: '運営',\n",
       " 285: 'お腹',\n",
       " 286: 'あり',\n",
       " 287: 'でも',\n",
       " 288: 'っ',\n",
       " 289: '食べ',\n",
       " 290: 'あぁ',\n",
       " 291: '＞',\n",
       " 292: 'しよ',\n",
       " 293: 'おぼえ',\n",
       " 294: '声',\n",
       " 295: 'とこ',\n",
       " 296: 'カメラ',\n",
       " 297: '仕事',\n",
       " 298: '燃える',\n",
       " 299: 'よく',\n",
       " 300: 'みたい',\n",
       " 301: 'どこ',\n",
       " 302: '時間',\n",
       " 303: '言う',\n",
       " 304: 'おけ',\n",
       " 305: 'オーラ',\n",
       " 306: '見',\n",
       " 307: 'イカ',\n",
       " 308: '筋肉',\n",
       " 309: '耽美',\n",
       " 310: '牡蠣',\n",
       " 311: '浮気',\n",
       " 312: '今',\n",
       " 313: 'マ',\n",
       " 314: '～！',\n",
       " 315: '～～～',\n",
       " 316: '🔥🔥🔥🔥🔥🔥',\n",
       " 317: 'インターハイ',\n",
       " 318: 'いむ',\n",
       " 319: '分',\n",
       " 320: '3',\n",
       " 321: 'サイズ',\n",
       " 322: 'ちゃんと',\n",
       " 323: '内股',\n",
       " 324: 'ポッキー',\n",
       " 325: '頑張っ',\n",
       " 326: '開演',\n",
       " 327: 'br',\n",
       " 328: '×',\n",
       " 329: 'より',\n",
       " 330: '月',\n",
       " 331: 'ませ',\n",
       " 332: '質問',\n",
       " 333: 'みんな',\n",
       " 334: 'えー',\n",
       " 335: 'がん',\n",
       " 336: 'おおい',\n",
       " 337: '古参',\n",
       " 338: '照れ',\n",
       " 339: 'さすが',\n",
       " 340: '急',\n",
       " 341: 'おもしろい',\n",
       " 342: 'こういう',\n",
       " 343: '１',\n",
       " 344: 'いう',\n",
       " 345: 'ず',\n",
       " 346: '茶器',\n",
       " 347: 'かけ',\n",
       " 348: 'やっぱ',\n",
       " 349: 'くっ',\n",
       " 350: '緊張',\n",
       " 351: 'はい',\n",
       " 352: 'ほんと',\n",
       " 353: 'ダンス',\n",
       " 354: 'お金',\n",
       " 355: '２',\n",
       " 356: 'すき',\n",
       " 357: 'おんぶ',\n",
       " 358: '可愛',\n",
       " 359: '年表',\n",
       " 360: 'なら',\n",
       " 361: '良い',\n",
       " 362: 'こと',\n",
       " 363: 'とき',\n",
       " 364: 'その',\n",
       " 365: 'おもしろかっ',\n",
       " 366: '詳しい',\n",
       " 367: '様',\n",
       " 368: '前',\n",
       " 369: '誰',\n",
       " 370: 'あげ',\n",
       " 371: '聞い',\n",
       " 372: 'たるみ',\n",
       " 373: 'どうか',\n",
       " 374: '欲しい',\n",
       " 375: 'ので',\n",
       " 376: '中',\n",
       " 377: '盛大',\n",
       " 378: '目',\n",
       " 379: '寝',\n",
       " 380: '的',\n",
       " 381: 'なれ',\n",
       " 382: 'やばい',\n",
       " 383: 'あっ',\n",
       " 384: '空間',\n",
       " 385: 'オンリー',\n",
       " 386: 'なんと',\n",
       " 387: 'さす',\n",
       " 388: '落ち',\n",
       " 389: '予選',\n",
       " 390: '系',\n",
       " 391: '年',\n",
       " 392: '５',\n",
       " 393: 'びん',\n",
       " 394: '重',\n",
       " 395: '専門',\n",
       " 396: '詳しく',\n",
       " 397: '入り',\n",
       " 398: '疲れ',\n",
       " 399: '十',\n",
       " 400: '五',\n",
       " 401: 'スパチャ',\n",
       " 402: '56',\n",
       " 403: '次',\n",
       " 404: 'タグ',\n",
       " 405: 'お客様',\n",
       " 406: 'ぇ',\n",
       " 407: 'お客',\n",
       " 408: 'ァ',\n",
       " 409: '全国',\n",
       " 410: '何',\n",
       " 411: '自宅',\n",
       " 412: 'ねえ',\n",
       " 413: 'jk',\n",
       " 414: '深',\n",
       " 415: '意味',\n",
       " 416: 'すげ',\n",
       " 417: 'yua',\n",
       " 418: 'いる',\n",
       " 419: '魅力',\n",
       " 420: '＆',\n",
       " 421: 'blank',\n",
       " 422: 'target',\n",
       " 423: '106148',\n",
       " 424: 'nico',\n",
       " 425: 'originalnews',\n",
       " 426: 'http',\n",
       " 427: 'href',\n",
       " 428: '告知',\n",
       " 429: '土産',\n",
       " 430: '生える',\n",
       " 431: 'まくっ',\n",
       " 432: 'www',\n",
       " 433: 'コメ',\n",
       " 434: 'かい',\n",
       " 435: 'てぇ',\n",
       " 436: '生',\n",
       " 437: 'やっぱり',\n",
       " 438: '近い',\n",
       " 439: 'お歌',\n",
       " 440: 'しおっ',\n",
       " 441: '認識',\n",
       " 442: '今日',\n",
       " 443: '独特',\n",
       " 444: 'ゃんのおしりしり',\n",
       " 445: 'お父さん',\n",
       " 446: '♥',\n",
       " 447: 'お待ち',\n",
       " 448: 'しばらく',\n",
       " 449: '生放送',\n",
       " 450: 'ニコニコ',\n",
       " 451: '後',\n",
       " 452: '教え',\n",
       " 453: '方法',\n",
       " 454: 'お送り',\n",
       " 455: 'キャスト',\n",
       " 456: 'バーチャル',\n",
       " 457: 'in',\n",
       " 458: '00',\n",
       " 459: '20',\n",
       " 460: 'おり',\n",
       " 461: '絵師',\n",
       " 462: '起き',\n",
       " 463: '勉強',\n",
       " 464: 'おわり',\n",
       " 465: '達',\n",
       " 466: 'おかげ',\n",
       " 467: 'おも',\n",
       " 468: 'ほほ',\n",
       " 469: 'フリ',\n",
       " 470: '頭',\n",
       " 471: 'kawaiimove',\n",
       " 472: '聞こ',\n",
       " 473: 'ぉ',\n",
       " 474: 'おおっ',\n",
       " 475: '狐',\n",
       " 476: '転生',\n",
       " 477: 'アングル',\n",
       " 478: 'エモ',\n",
       " 479: 'つけろ',\n",
       " 480: '時',\n",
       " 481: '近く',\n",
       " 482: '→',\n",
       " 483: '４',\n",
       " 484: 'vive',\n",
       " 485: 'ちっちゃい',\n",
       " 486: '絵',\n",
       " 487: 'かぁ',\n",
       " 488: 'かも',\n",
       " 489: 'うーん',\n",
       " 490: 'かっこ',\n",
       " 491: 'そ',\n",
       " 492: 'べし',\n",
       " 493: 'ぽい',\n",
       " 494: 'かん',\n",
       " 495: '斜め',\n",
       " 496: '困り',\n",
       " 497: 'かわり',\n",
       " 498: 'がんばれ',\n",
       " 499: 'ぎぃ',\n",
       " 500: 'くる',\n",
       " 501: '実質',\n",
       " 502: 'ちゃう',\n",
       " 503: '練習',\n",
       " 504: 'まず',\n",
       " 505: '役所',\n",
       " 506: 'つの',\n",
       " 507: 'ワード',\n",
       " 508: 'すご',\n",
       " 509: 'きり',\n",
       " 510: 'ッ',\n",
       " 511: 'パワー',\n",
       " 512: 'せい',\n",
       " 513: '鏡',\n",
       " 514: '福利',\n",
       " 515: '無理',\n",
       " 516: 'そういう',\n",
       " 517: '来',\n",
       " 518: 'イチャイチャ',\n",
       " 519: 'よかっ',\n",
       " 520: '生え',\n",
       " 521: '３',\n",
       " 522: 'おさ',\n",
       " 523: '私',\n",
       " 524: 'こま',\n",
       " 525: 'おちつい',\n",
       " 526: '宣伝',\n",
       " 527: 'cd',\n",
       " 528: '作っ',\n",
       " 529: 'とっ',\n",
       " 530: 'がんばっ',\n",
       " 531: '拾っ',\n",
       " 532: '関連',\n",
       " 533: '大',\n",
       " 534: 'もどっ',\n",
       " 535: 'おなか',\n",
       " 536: 'おわら',\n",
       " 537: '大丈夫',\n",
       " 538: '中村',\n",
       " 539: '甘い',\n",
       " 540: 'つきゃ',\n",
       " 541: '草刈り',\n",
       " 542: 'お祝い',\n",
       " 543: 'ボール',\n",
       " 544: '一緒',\n",
       " 545: 'いえ',\n",
       " 546: '：',\n",
       " 547: '答え',\n",
       " 548: '良かっ',\n",
       " 549: '大事',\n",
       " 550: '受け',\n",
       " 551: '途中',\n",
       " 552: 'ねー',\n",
       " 553: 'くらい',\n",
       " 554: '9',\n",
       " 555: 'ひと',\n",
       " 556: 'りつ',\n",
       " 557: 'へそ',\n",
       " 558: '致し',\n",
       " 559: 'まる',\n",
       " 560: 'みん',\n",
       " 561: '誕生',\n",
       " 562: 'じ',\n",
       " 563: '世知辛い',\n",
       " 564: 'のに',\n",
       " 565: 'おわっ',\n",
       " 566: '照れる',\n",
       " 567: '日本',\n",
       " 568: '側',\n",
       " 569: '本気',\n",
       " 570: '＾～',\n",
       " 571: '見る',\n",
       " 572: 'ところで',\n",
       " 573: '覚え',\n",
       " 574: 'k',\n",
       " 575: 'るこく',\n",
       " 576: 'コンビニ',\n",
       " 577: 'みえ',\n",
       " 578: 'なり',\n",
       " 579: 'ーーーーー',\n",
       " 580: '不可避',\n",
       " 581: '収蔵',\n",
       " 582: 'がち',\n",
       " 583: '会',\n",
       " 584: '即売',\n",
       " 585: '動き',\n",
       " 586: '可愛い',\n",
       " 587: 'とか',\n",
       " 588: '出る',\n",
       " 589: '明日',\n",
       " 590: '彡',\n",
       " 591: 'コ',\n",
       " 592: 'く',\n",
       " 593: '白い',\n",
       " 594: '者',\n",
       " 595: 'たしか',\n",
       " 596: '出',\n",
       " 597: '用語',\n",
       " 598: 'いっ',\n",
       " 599: '上がっ',\n",
       " 600: '息',\n",
       " 601: '刺さっ',\n",
       " 602: '被っ',\n",
       " 603: '再現',\n",
       " 604: '狼',\n",
       " 605: '妄想',\n",
       " 606: '放送',\n",
       " 607: 'ドッジボール',\n",
       " 608: '言葉',\n",
       " 609: 'マリオ',\n",
       " 610: 'リアル',\n",
       " 611: 'でる',\n",
       " 612: '飲ん',\n",
       " 613: 'フローチャート',\n",
       " 614: '匂い',\n",
       " 615: '東海道',\n",
       " 616: 'ケット',\n",
       " 617: 'プロレス',\n",
       " 618: '偶数',\n",
       " 619: '音',\n",
       " 620: '説',\n",
       " 621: '委員',\n",
       " 622: '言い値',\n",
       " 623: 'おーい',\n",
       " 624: 'にて',\n",
       " 625: 'ィ',\n",
       " 626: 'やろ',\n",
       " 627: 'vr',\n",
       " 628: '七草',\n",
       " 629: 'かざっ',\n",
       " 630: '；∀；',\n",
       " 631: 'すれ',\n",
       " 632: '○',\n",
       " 633: 'うさ',\n",
       " 634: '小説',\n",
       " 635: '曲',\n",
       " 636: '歌',\n",
       " 637: 'ちまっ',\n",
       " 638: 'なんぞ',\n",
       " 639: '心',\n",
       " 640: '６',\n",
       " 641: '９',\n",
       " 642: 'ガニマタ',\n",
       " 643: 'しとる',\n",
       " 644: 'なおせ',\n",
       " 645: 'ぁ',\n",
       " 646: '事件',\n",
       " 647: '甘',\n",
       " 648: 'ボーガー',\n",
       " 649: 'ｗｗｗｗｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 650: 'ｗｗｗｗｗｗｗｗｗｗｗｗｗｗｗｗ',\n",
       " 651: 'ざ',\n",
       " 652: '～♪',\n",
       " 653: '🔥🔥🔥🔥🔥🔥🔥',\n",
       " 654: '🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥',\n",
       " 655: '🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥',\n",
       " 656: '🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥',\n",
       " 657: 'ゴクッ',\n",
       " 658: '共感',\n",
       " 659: '素',\n",
       " 660: 'えな',\n",
       " 661: '一体',\n",
       " 662: '謀反',\n",
       " 663: '溢れ',\n",
       " 664: '満ち',\n",
       " 665: 'なま',\n",
       " 666: '無かっ',\n",
       " 667: 'move',\n",
       " 668: 's',\n",
       " 669: '食',\n",
       " 670: 'ゃ',\n",
       " 671: 'ち',\n",
       " 672: 'リハ',\n",
       " 673: 'rt',\n",
       " 674: 'ツイッター',\n",
       " 675: 'ww',\n",
       " 676: '乱立',\n",
       " 677: 'wwwww',\n",
       " 678: 'ぇてぇよお',\n",
       " 679: '始まる',\n",
       " 680: '電話',\n",
       " 681: '知っ',\n",
       " 682: 'ートリックスター',\n",
       " 683: '聞き',\n",
       " 684: '付け',\n",
       " 685: '体',\n",
       " 686: '入れる',\n",
       " 687: '手',\n",
       " 688: 'おとなしい',\n",
       " 689: '見捨てる',\n",
       " 690: '☆',\n",
       " 691: 'イン',\n",
       " 692: 'チャージ',\n",
       " 693: '❤',\n",
       " 694: '楽しみ',\n",
       " 695: '幸い',\n",
       " 696: 'いただける',\n",
       " 697: '維持',\n",
       " 698: 'モチベーション',\n",
       " 699: 'お世話',\n",
       " 700: '息子',\n",
       " 701: 'ゃんかわいい',\n",
       " 702: 'あと',\n",
       " 703: 'テスト',\n",
       " 704: '期末',\n",
       " 705: '学生',\n",
       " 706: '卵',\n",
       " 707: 'まあ',\n",
       " 708: 'きゃあ',\n",
       " 709: 'あい',\n",
       " 710: 'ど',\n",
       " 711: 'あし',\n",
       " 712: 'ありがたい',\n",
       " 713: 'abema',\n",
       " 714: '書い',\n",
       " 715: '尻',\n",
       " 716: '会え',\n",
       " 717: 'いや',\n",
       " 718: 'ぃぃ',\n",
       " 719: '映る',\n",
       " 720: 'すする',\n",
       " 721: 'おかわ',\n",
       " 722: 'つた',\n",
       " 723: 'せよ',\n",
       " 724: '持た',\n",
       " 725: '届く',\n",
       " 726: '払お',\n",
       " 727: '料',\n",
       " 728: '出演',\n",
       " 729: '歌お',\n",
       " 730: '貰お',\n",
       " 731: '手帳',\n",
       " 732: '障害',\n",
       " 733: 'うふ',\n",
       " 734: 'うふふ',\n",
       " 735: 'ふたり',\n",
       " 736: 'どうぞ',\n",
       " 737: 'えらい',\n",
       " 738: '使う',\n",
       " 739: 'ぷに',\n",
       " 740: 'ぃにっとる',\n",
       " 741: 'いん',\n",
       " 742: 'ゃんこくお',\n",
       " 743: 'ぉぉおおぉおぉおおお',\n",
       " 744: 'ぉぉおおおお',\n",
       " 745: 'わぁ',\n",
       " 746: '事務所',\n",
       " 747: '年金',\n",
       " 748: '世界',\n",
       " 749: '異',\n",
       " 750: '８',\n",
       " 751: 'もうすぐ',\n",
       " 752: '無い',\n",
       " 753: 'ハースストーン',\n",
       " 754: '悔しい',\n",
       " 755: 'しろ',\n",
       " 756: 'はやい',\n",
       " 757: 'はじまっ',\n",
       " 758: 'おおう',\n",
       " 759: 'ふお',\n",
       " 760: 'テンパ',\n",
       " 761: 'じゃれ',\n",
       " 762: 'みの',\n",
       " 763: '最先端',\n",
       " 764: '鍵っ子',\n",
       " 765: 'おちつけ',\n",
       " 766: 'タイプ',\n",
       " 767: 'さまよっ',\n",
       " 768: '２月',\n",
       " 769: 'お茶',\n",
       " 770: '茶色',\n",
       " 771: '拾える',\n",
       " 772: '必須',\n",
       " 773: 'vrc',\n",
       " 774: '迷っ',\n",
       " 775: 'htc',\n",
       " 776: 'おすすめ',\n",
       " 777: 'こまっ',\n",
       " 778: 'つくる',\n",
       " 779: 'テクスチャ',\n",
       " 780: '拾う',\n",
       " 781: '版',\n",
       " 782: '壺',\n",
       " 783: '休み',\n",
       " 784: '←',\n",
       " 785: 'ゆらゆら',\n",
       " 786: 'つられ',\n",
       " 787: '笑顔',\n",
       " 788: '足',\n",
       " 789: '一投',\n",
       " 790: '一挙',\n",
       " 791: '間',\n",
       " 792: 'しぐさ',\n",
       " 793: '考え',\n",
       " 794: 'あそぶ',\n",
       " 795: 'こめ',\n",
       " 796: 'ちっ',\n",
       " 797: 'ちいさく',\n",
       " 798: 'デレデレ',\n",
       " 799: '純正',\n",
       " 800: 'わっ',\n",
       " 801: 'すく',\n",
       " 802: 'ドキドキ',\n",
       " 803: 'twiitter',\n",
       " 804: '絡まっ',\n",
       " 805: '指',\n",
       " 806: 'カタコト',\n",
       " 807: '怒涛',\n",
       " 808: '被る',\n",
       " 809: '旧',\n",
       " 810: '最初',\n",
       " 811: 'ウインク',\n",
       " 812: 'カッコ',\n",
       " 813: 'キャット',\n",
       " 814: '場繋ぎ',\n",
       " 815: '稼ぎ',\n",
       " 816: '尺',\n",
       " 817: 'つなぎ',\n",
       " 818: '場',\n",
       " 819: '待機',\n",
       " 820: 'はぁ',\n",
       " 821: 'きらきら',\n",
       " 822: '指切り',\n",
       " 823: '画面',\n",
       " 824: '眉',\n",
       " 825: '耳',\n",
       " 826: '超',\n",
       " 827: '花',\n",
       " 828: 'チラ',\n",
       " 829: '像',\n",
       " 830: 'うの',\n",
       " 831: '広場',\n",
       " 832: '子',\n",
       " 833: 'きつい',\n",
       " 834: 'きつね',\n",
       " 835: 'ひ',\n",
       " 836: 'おち',\n",
       " 837: '毎週',\n",
       " 838: 'コーナー',\n",
       " 839: '解決',\n",
       " 840: 'ぐっ',\n",
       " 841: '行き',\n",
       " 842: '暴力',\n",
       " 843: '使え',\n",
       " 844: '腰',\n",
       " 845: 'ジェバンニ',\n",
       " 846: 'しい',\n",
       " 847: 'しまう',\n",
       " 848: '連続',\n",
       " 849: 'じい',\n",
       " 850: '前列',\n",
       " 851: '最',\n",
       " 852: 'じゃん',\n",
       " 853: '俺',\n",
       " 854: 'じゃー',\n",
       " 855: '仕草',\n",
       " 856: '小指',\n",
       " 857: 'だい',\n",
       " 858: '神話',\n",
       " 859: '解答',\n",
       " 860: 'せき',\n",
       " 861: 'おもしろ',\n",
       " 862: '入っ',\n",
       " 863: '充実',\n",
       " 864: '厚生',\n",
       " 865: 'そうですね',\n",
       " 866: '掛かっ',\n",
       " 867: '出来る',\n",
       " 868: 'ゲーム',\n",
       " 869: '実装',\n",
       " 870: '二刀流',\n",
       " 871: '絵かき',\n",
       " 872: '愛らしい',\n",
       " 873: '飛ばす',\n",
       " 874: 'マジレス',\n",
       " 875: '隙',\n",
       " 876: 'ぞい',\n",
       " 877: '結構',\n",
       " 878: 'おこっ',\n",
       " 879: 'ふしぎ',\n",
       " 880: 'おしかっ',\n",
       " 881: 'たおっ',\n",
       " 882: 'たかっ',\n",
       " 883: '当たり前',\n",
       " 884: '皆様',\n",
       " 885: 'ご苦労',\n",
       " 886: 'なおっ',\n",
       " 887: '晩',\n",
       " 888: '変わっ',\n",
       " 889: 'saber',\n",
       " 890: 'beat',\n",
       " 891: '背面',\n",
       " 892: '掃除',\n",
       " 893: '養わ',\n",
       " 894: '暮らし',\n",
       " 895: '雑草',\n",
       " 896: 'たち',\n",
       " 897: '化',\n",
       " 898: '的確',\n",
       " 899: '対応',\n",
       " 900: 'たまる',\n",
       " 901: '分間',\n",
       " 902: 'お披露目',\n",
       " 903: 'デビュー',\n",
       " 904: '鍛える',\n",
       " 905: '筋',\n",
       " 906: '思お',\n",
       " 907: 'だっこ',\n",
       " 908: 'お姫様',\n",
       " 909: 'うまれ',\n",
       " 910: '属性',\n",
       " 911: 'ちり',\n",
       " 912: 'トー',\n",
       " 913: 'フッ',\n",
       " 914: 'っす',\n",
       " 915: 'いきゃ',\n",
       " 916: 'しゃれ',\n",
       " 917: 'そのまま',\n",
       " 918: '新曲',\n",
       " 919: '発売',\n",
       " 920: 'たて',\n",
       " 921: 'とい',\n",
       " 922: 'なおし',\n",
       " 923: 'おせ',\n",
       " 924: '年齢',\n",
       " 925: '実',\n",
       " 926: '鍛え',\n",
       " 927: '進化',\n",
       " 928: 'カーナビ',\n",
       " 929: '組',\n",
       " 930: '草原',\n",
       " 931: 'おさない',\n",
       " 932: '100',\n",
       " 933: '名残惜しい',\n",
       " 934: '提供',\n",
       " 935: '環境',\n",
       " 936: '舞台',\n",
       " 937: 'たのしかっ',\n",
       " 938: 'セン',\n",
       " 939: 'パイ',\n",
       " 940: 'つらい',\n",
       " 941: '買え',\n",
       " 942: '在庫',\n",
       " 943: 'エール',\n",
       " 944: '沸か',\n",
       " 945: '力',\n",
       " 946: '頑張る',\n",
       " 947: '口',\n",
       " 948: '絡み',\n",
       " 949: 'いも',\n",
       " 950: 'れる',\n",
       " 951: '引っ張ら',\n",
       " 952: 'たくさん',\n",
       " 953: 'ーーーーーー',\n",
       " 954: 'とん',\n",
       " 955: '師',\n",
       " 956: 'ロゴ',\n",
       " 957: 'よっ',\n",
       " 958: '苦労',\n",
       " 959: 'ぁのじゃおじも',\n",
       " 960: 'ノッ',\n",
       " 961: '音楽',\n",
       " 962: '自然',\n",
       " 963: '慣れ',\n",
       " 964: 'だいぶ',\n",
       " 965: '進行',\n",
       " 966: '申し上げる',\n",
       " 967: 'お祈り',\n",
       " 968: '為',\n",
       " 969: 'のぞき込む',\n",
       " 970: '広がっ',\n",
       " 971: '裾野',\n",
       " 972: 'いけ',\n",
       " 973: '闇',\n",
       " 974: '咳',\n",
       " 975: '朗報',\n",
       " 976: '存在',\n",
       " 977: 'しれ',\n",
       " 978: 'つい',\n",
       " 979: '戦い',\n",
       " 980: '置い',\n",
       " 981: 'なさい',\n",
       " 982: 'なやみ',\n",
       " 983: 'アイ',\n",
       " 984: 'お互い',\n",
       " 985: '紅茶',\n",
       " 986: 'による',\n",
       " 987: 'ソフト',\n",
       " 988: '使い',\n",
       " 989: 'つまり',\n",
       " 990: 'なおさら',\n",
       " 991: '企業',\n",
       " 992: '他',\n",
       " 993: '人形',\n",
       " 994: 'ギャップ',\n",
       " 995: '余計',\n",
       " 996: '回し',\n",
       " 997: '使い手',\n",
       " 998: 'ユニーク',\n",
       " 999: 'ユニティ',\n",
       " 1000: '睡眠',\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "reverse_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_testoutput = [val for val in token_testoutput if val > 0]\n",
    "pred_seq = [reverse_word_map[key_val] for key_val in token_testoutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neglect']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
